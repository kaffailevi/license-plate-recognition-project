License Plate Recognition Project

## KÃ©szÃ­tette:
- **Kaffai Levente**, **GÃ¡ll Benedek**, **GÃ¡spÃ¡r TamÃ¡s** 
- **SzÃ¡mÃ­tÃ³gÃ©pes IrÃ¡nyÃ­tÃ¡si Rendszerek I**

## TartalomjegyzÃ©k
1. [Projekt ÃttekintÃ©s](#projekt-Ã¡ttekintÃ©s)
2. [Technikai Stack](#technikai-stack)
3. [Notebook Szerkezete (licence-plate-recognition. ipynb)](#notebook-szerkezete)
6. [KFold Cross-Validation](#kfold-cross-validation)
7. [MetrikÃ¡k Ã‰rtelmezÃ©se](#metrikÃ¡k-Ã©rtelmezÃ©se)
8. [EredmÃ©nyek ElemzÃ©se](#eredmÃ©nyek-elemzÃ©se)
9. [Javaslatok Ã©s FejlesztÃ©si IrÃ¡nyok](#javaslatok-Ã©s-fejlesztÃ©si-irÃ¡nyok)

---

## Projekt ÃttekintÃ©s

### Mit csinÃ¡lunk?
Ezt a projektet **autÃ³ rendszÃ¡mtÃ¡blÃ¡k automatikus felismerÃ©sÃ©re** alapoztuk. Az objektum detekciÃ³s feladat a kÃ¶vetkezÅ‘ket jelenti:
- **Input**: FotÃ³ egy autÃ³rÃ³l
- **Output**: Bounding box koordinÃ¡tÃ¡k a rendszÃ¡mtÃ¡bla helyÃ©rÅ‘l
- **MÃ³dszer**: Deep Learning + PyTorch + KFold Cross-Validation

### MiÃ©rt fontos?
- ğŸš— Intelligens parkolÃ³rendszerek
- ğŸ“¹ KÃ¶zlekedÃ©si kamera-felÃ¼gyeleti rendszerek
- ğŸš“ RendÅ‘rsÃ©gi nyomozÃ¡sok tÃ¡mogatÃ¡sa
- ğŸª ParkolÃ³hÃ¡z belÃ©pÃ©svezÃ©rlÃ©s

### Adathalmaz Info
- **ForrÃ¡s**: Kaggle - Car Plate Detection Dataset
- **KÃ©pek**: 433 darab PNG formÃ¡tumÃº kÃ©p
- **AnnotÃ¡ciÃ³k**: Pascal VOC XML format
- **FelhasznÃ¡lÃ¡s**: 80% tanÃ­tÃ¡s, 20% validÃ¡ciÃ³ (KFold mÃ³dszerrel)

---

## Technikai Stack

```
ProgramozÃ¡si Nyelv:      Python 3.x
Deep Learning:           PyTorch 2.x
KÃ©pfeldolgozÃ¡s:        OpenCV (cv2)
KÃ©ptranszformÃ¡ciÃ³k:    Torchvision
VizualizÃ¡ciÃ³:          Matplotlib
XML kezelÃ©s:           xml.etree.ElementTree
Notebook:              Jupyter
Platform:              Kaggle Notebooks
```

---

## Notebook Szerkezete

A `licence-plate-recognition.ipynb` notebook **kÃ©t fÅ‘ cellÃ¡bÃ³l** Ã¡ll:

### **1. Cella â€“ Adathalmaz BetÃ¶ltÃ©s Ã©s ElÅ‘feldolgozÃ¡s**

#### 1.1 Import Ã©s SegÃ©dosztÃ¡lyok

```python
import os, glob, cv2, torch, xml.etree.ElementTree as ET
import matplotlib.pyplot as plt, random
from torch.utils.data import Dataset
import torchvision.transforms as T
```

**Mit importÃ¡lunk?**
- `os, glob`: FÃ¡jlrendszer navigÃ¡ciÃ³
- `cv2`: KÃ©pfeldolgozÃ¡s (OpenCV)
- `torch`: PyTorch framework
- `ET`: XML annotÃ¡ciÃ³k olvasÃ¡sa
- `Dataset`: PyTorch adathalmaz alaposztÃ¡ly
- `transforms`: KÃ©ptranszformÃ¡ciÃ³k

---

#### 1.2 Egyedi AugmentÃ¡ciÃ³s OsztÃ¡lyok

##### **A) AddGaussianNoise â€“ VÃ©letlenszerÅ± Zaj**

```python
class AddGaussianNoise(object):
    """
    CÃ©lja: Kamera zajtÃ³l valÃ³ robusztussÃ¡g. 
    Gaussian (normÃ¡lis) eloszlÃ¡sÃº zaj hozzÃ¡adÃ¡sa a pixel Ã©rtÃ©kekhez.
    """
    def __init__(self, mean=0., std=0.1):
        self.std = std      # SzÃ³rÃ¡s (1-5 kÃ¶zÃ¶tt:  erÅ‘s zaj)
        self.mean = mean    # Ãtlag (Ã¡ltalÃ¡ban 0)
        
    def __call__(self, tensor):
        # Random zaj generÃ¡lÃ¡sa
        noise = torch.randn(tensor.size()) * self.std + self.mean
        # HozzÃ¡adÃ¡s a kÃ©phez, majd clipping 0-1 tartomÃ¡nyra
        return torch.clamp(tensor + noise, 0., 1.)
```

**Hogyan mÅ±kÃ¶dik?**
1. Gaussian eloszlÃ¡sÃº random szÃ¡mok generÃ¡lÃ¡sa
2. Pixel Ã©rtÃ©kekhez adÃ¡s
3. Ã‰rtÃ©kek csonkolÃ¡sa 0-1 kÃ¶zÃ© (kÃ©pformÃ¡tum megÅ‘rzÃ©se)

**ParamÃ©ter Ã©rtelmezÃ©se:**
- `std=0.05`: Enyhe zaj (valÃ³svilÃ¡gszerÅ±)
- `std=0.1`: KÃ¶zepes zaj (viharos napok)
- `std=0.2+`: ErÅ‘s zaj (rossz kameraminÅ‘sÃ©g)

---

##### **B) RandomBlur â€“ VÃ©letlenszerÅ± ElhomÃ¡lyosÃ­tÃ¡s**

```python
class RandomBlur(object):
    """
    CÃ©lja:  MozgatÃ¡si elmosÃ³dÃ¡s szimulÃ¡lÃ¡sa (autÃ³ mozgÃ¡sa kÃ¶zben).
    """
    def __init__(self, p=0.5):
        self.p = p  # 50% valÃ³szÃ­nÅ±sÃ©g alkalmazÃ¡sra
        self.blur = T.GaussianBlur(
            kernel_size=(5, 9),      # Kernel mÃ©ret (aszimmetrikus = mozgÃ¡s-szerÅ±)
            sigma=(0.1, 5)           # SzÃ³rÃ¡s tartomÃ¡ny (0.1-5 kÃ¶zÃ¶tt)
        )

    def __call__(self, img):
        if random.random() < self.p:
            return self.blur(img)
        return img  # Eredeti kÃ©p, ha nem aktivÃ¡lÃ³dik
```

**MiÃ©rt aszimmetrikus kernel?**
- `(5, 9)` = 5 pixel fÃ¼ggÅ‘legesen, 9 pixel vÃ­zszintesen
- Az autÃ³ Ã¡ltalÃ¡ban vÃ­zszintesen mozog â†’ reÃ¡lis szimulÃ¡ciÃ³s

**ValÃ³s alkalmazÃ¡s:**
- Gyors autÃ³:  Kernel 5Ã—25 is lehet
- LassÃº autÃ³: Kernel 3Ã—7 elegendÅ‘

---

#### 1.3 TranszformÃ¡ciÃ³s Pipeline

```python
def get_transform(train):
    """
    Ã–sszeÃ©pÃ­tjÃ¼k az Ã¶sszes transzformÃ¡ciÃ³t.
    'train' paramÃ©terbÅ‘l fÃ¼ggÅ‘en eltÃ©rÅ‘ augmentÃ¡ciÃ³. 
    """
    transforms = []
    
    # 1. MINDIG:  KÃ©p RGB pixel Ã©rtÃ©keket 0-1 tartomÃ¡nyÃº tensorokkÃ¡ alakÃ­tja
    transforms.append(T. ToTensor())
    
    if train:  # â† CSAK TANÃTÃS ALATT! 
        # A.  SzÃ­n Ã©s FÃ©nyerÅ‘ VariÃ¡ciÃ³
        # ValÃ³svilÃ¡gszerÅ± megvilÃ¡gÃ­tÃ¡s szimulÃ¡lÃ¡sa
        transforms.append(T. ColorJitter(
            brightness=0.4,   # Â±40% fÃ©nyerÅ‘-vÃ¡ltozÃ¡s
            contrast=0.4,     # Â±40% kontraszt-vÃ¡ltozÃ¡s
            saturation=0.4,   # Â±40% telÃ­tettsÃ©g-vÃ¡ltozÃ¡s
            hue=0.1           # Â±10% szÃ­n-eltolÃ³ (pl. sÃ¡rgaâ†’narancs)
        ))
        
        # B. Gaussian Zaj HozzÃ¡adÃ¡sa (50% esÃ©llyel)
        transforms.append(T.RandomApply(
            [AddGaussianNoise(0., 0.05)],  # Custom noise osztÃ¡lyunk
            p=0.5  # 50% esÃ©ly
        ))
        
        # C. Gaussian ElmosÃ³dÃ¡s (50% esÃ©llyel)
        transforms.append(T.RandomApply(
            [T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2. 0))],
            p=0.5
        ))
    
    return T.Compose(transforms)  # Ã–sszes transzformÃ¡ciÃ³ egymÃ¡s utÃ¡n
```

**MiÃ©rt nincs augmentÃ¡ciÃ³ a tesztnÃ©l?**
- Teszt:  ValÃ³svilÃ¡got kell szimulÃ¡lnia (nem akartunk kÃ©p-zaj)
- TanÃ­tÃ¡s: Modell robusztussÃ¡ tÃ©tele (zaj, elmosÃ³dÃ¡s szÃ¼ksÃ©ges)

**AugmentÃ¡ciÃ³s sorrend:**
```
Input KÃ©p
    â†“
1. ToTensor (0-1 normalizÃ¡lÃ¡s)
    â†“ (CSAK TANÃTÃS)
2. ColorJitter (szÃ­n variÃ¡ciÃ³)
    â†“ (50%)
3. AddGaussianNoise (zaj)
    â†“ (50%)
4. GaussianBlur (elmosÃ³dÃ¡s)
    â†“
Output AugmentÃ¡lt KÃ©p
```

---

#### 1.4 Custom CarPlateDataset OsztÃ¡ly

Ez a **legalapvetÅ‘bb** rÃ©sz!  PyTorch Dataset interfÃ©szt implementÃ¡lja.

```python
class CarPlateDataset(Dataset):
    """
    RendszÃ¡mtÃ¡bla-detekciÃ³s adathalmaz.
    KÃ©p + XML annotÃ¡ciÃ³ pÃ¡rosÃ­tÃ¡sÃ©rt felelÅ‘s.
    """
    
    def __init__(self, images_dir, annotations_dir, transforms=None):
        """
        InicializÃ¡ciÃ³:  KÃ©pek Ã©s annotÃ¡ciÃ³k Ã¶sszerendelÃ©se.
        """
        self.images_dir = images_dir          # pl. '/kaggle/input/. ../images'
        self.annotations_dir = annotations_dir # pl. '/kaggle/input/. ../annotations'
        self.transforms = transforms          # TranszformÃ¡ciÃ³s pipeline
        
        # Ã–sszes PNG kÃ©p keresÃ©se az images_dir-ban
        self.image_files = sorted(glob.glob(os.path.join(images_dir, '*.png')))
        
        # FILTEREZÃ‰S: Csak azok a kÃ©pek, amelyeknek van XML-je
        self.valid_images = []
        for img_path in self.image_files:
            # Pl. 'car_001. png' â†’ 'car_001'
            base_name = os.path.basename(img_path)
            file_name_no_ext = os.path.splitext(base_name)[0]
            
            # Megkeres:  'annotations/car_001.xml'
            annot_path = os.path. join(self.annotations_dir, file_name_no_ext + '.xml')
            
            # Ha az XML lÃ©tezik, hozzÃ¡adjuk az Ã©rvÃ©nyes listÃ¡hoz
            if os.path.exists(annot_path):
                self.valid_images.append(img_path)
    
    def __len__(self):
        """
        PyTorch megkÃ¶veteli ezt:  az adathalmaz mÃ©rete.
        """
        return len(self.valid_images)
    
    def __getitem__(self, idx):
        """
        PyTorch megkÃ¶veteli ezt: egy sample (kÃ©p + target) visszaadÃ¡sa.
        """
        # Index alapjÃ¡n egy kÃ©p elÃ©rÃ©se
        img_path = self.valid_images[idx]
        base_name = os.path.basename(img_path)
        file_name_no_ext = os.path.splitext(base_name)[0]
        annot_path = os.path. join(self.annotations_dir, file_name_no_ext + '.xml')
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LÃ‰PÃ‰S 1: KÃ‰P BETÃ–LTÃ‰SE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        image = cv2.imread(img_path)              # OpenCV: BGR betÃ¶ltÃ©s
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR â†’ RGB konverziÃ³
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LÃ‰PÃ‰S 2: XML ANNOTÃCIÃ“K BETÃ–LTÃ‰SE (BOUNDING BOXOK)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        boxes = []
        tree = ET.parse(annot_path)  # XML fÃ¡jl olvasÃ¡sa
        root = tree.getroot()
        
        # Minden <object> tagen belÃ¼l van egy <bndbox>
        for obj in root.findall('object'):
            bbox = obj.find('bndbox')
            # XML-bÅ‘l koordinÃ¡tÃ¡k kinyerÃ©se:  (x_min, y_min, x_max, y_max)
            xmin = int(bbox.find('xmin').text)
            ymin = int(bbox.find('ymin').text)
            xmax = int(bbox.find('xmax').text)
            ymax = int(bbox.find('ymax').text)
            
            boxes.append([xmin, ymin, xmax, ymax])
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LÃ‰PÃ‰S 3: TENSOROKKÃ KONVERTÃLÃS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        boxes = torch.as_tensor(boxes, dtype=torch.float32)
        
        # Minden box-hez 1-es label (=rendszÃ¡mtÃ¡bla)
        # TÃ¶bb osztÃ¡ly esetÃ©n: 0=rendszÃ¡m, 1=ember, 2=jÃ¡rmÅ±, stb.
        labels = torch. ones((len(boxes),), dtype=torch.int64)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LÃ‰PÃ‰S 4: TARGET DICTIONARY Ã–SSZEÃLLÃTÃSA
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        target = {}
        target["boxes"] = boxes      # Bounding box koordinÃ¡tÃ¡k
        target["labels"] = labels    # OsztÃ¡ly label (mindegyik = 1)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LÃ‰PÃ‰S 5: TRANSZFORMÃCIÃ“K ALKALMAZÃSA (ha szÃ¼ksÃ©ges)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.transforms:
            image = self.transforms(image)
        
        return image, target  # KÃ©p Ã©s cÃ©lÃ©rtÃ©kek visszaadÃ¡sa
```

**Pascal VOC XML FormÃ¡tum Referencia:**
```xml
<?xml version="1.0" encoding="utf-8"?>
<annotation>
  <folder>images</folder>
  <filename>car_001.png</filename>
  <path>. ../car_001.png</path>
  <source>
    <database>Car Plate Detection</database>
  </source>
  <size>
    <width>640</width>
    <height>480</height>
    <depth>3</depth>
  </size>
  <segmented>0</segmented>
  <object>
    <name>plate</name>
    <pose>Unspecified</pose>
    <truncated>0</truncated>
    <difficult>0</difficult>
    <bndbox>
      <xmin>120</xmin>    â† Bal szÃ©l (pixel)
      <ymin>80</ymin>     â† FelsÅ‘ szÃ©l (pixel)
      <xmax>280</xmax>    â† Jobb szÃ©l (pixel)
      <ymax>140</ymax>    â† AlsÃ³ szÃ©l (pixel)
    </bndbox>
  </object>
</annotation>
```

---

#### 1.5 Adathalmaz InicializÃ¡ciÃ³

```python
# Ãštvonalak Kaggle-hez
IMG_DIR = '/kaggle/input/car-plate-detection/images'
ANNOT_DIR = '/kaggle/input/car-plate-detection/annotations'

# Dataset lÃ©trehozÃ¡sa (transzformÃ¡ciÃ³k NÃ‰ LKÃœLI, csak vizualizÃ¡ciÃ³hoz)
dataset = CarPlateDataset(IMG_DIR, ANNOT_DIR)

print(f"Az adathalmaz mÃ©rete: {len(dataset)} kÃ©p.")
# OUTPUT: Az adathalmaz mÃ©rete: 433 kÃ©p. 
```

---

#### 1.6 VizualizÃ¡ciÃ³ â€“ AnnotÃ¡ciÃ³k EllenÅ‘rzÃ©se

```python
import matplotlib.pyplot as plt
import random

# 5 vÃ©letlen kÃ©p kivÃ¡lasztÃ¡sa
indices = random.sample(range(len(dataset)), 5)

plt.figure(figsize=(20, 10))

for i, idx in enumerate(indices):
    # Dataset-bÅ‘l egy sample
    image, target = dataset[idx]
    
    # MÃ¡solat a rajzolÃ¡shoz (memÃ³riavÃ©delem)
    img_viz = image.copy()
    
    # Bounding box-ok kinyerÃ©se
    boxes = target["boxes"]. numpy()
    
    # Minden dobozhoz:  zÃ¶ld nÃ©gyzet rajzolÃ¡sa
    for box in boxes: 
        x_min, y_min, x_max, y_max = box. astype(int)
        
        # ZÃ¶ld tÃ©glalap (RGB: (R=0, G=255, B=0))
        cv2.rectangle(img_viz, (x_min, y_min), (x_max, y_max), (0, 255, 0), 3)
        
        # "Plate" szÃ¶veg a doboz felÃ©
        cv2.putText(img_viz, "Plate", (x_min, y_min - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
    
    # Subplot-ban megjelenÃ­tÃ©s
    plt. subplot(1, 5, i + 1)
    plt.imshow(img_viz)
    plt.axis('off')
    plt.title(f"Index: {idx}")

plt.show()
```

**Kimenet:**
- 1Ã—5 Ã¶sszesen 5 kÃ©p
- ZÃ¶ld bounding box a rendszÃ¡mtÃ¡blÃ¡k kÃ¶rÃ¼l
- "Plate" felirat minden box felett

---

### **2. Cella â€“ Modell TanÃ­tÃ¡s Ã©s KFold ValidÃ¡ciÃ³**

*(Ez a cella nem teljes a megadott kÃ³dban, de a tanÃ­tÃ¡si folyamatot Ã­rnÃ¡ le)*

---

## KFold Cross-Validation

### MiÃ©rt a KFold? 

**NormÃ¡l Train-Test Split (ROSSZ):**
```
Teljes adathalmaz (433 kÃ©p)
â”œâ”€â”€ TanÃ­tÃ¡s (80% = 346 kÃ©p)
â””â”€â”€ Teszt (20% = 87 kÃ©p)
     â†“
PROBLÃ‰MA: Ha vÃ©letlenÃ¼l kÃ¶nnyÅ± kÃ©pek kerÃ¼lnek a tesztbe?
         â†’ TÃºl jÃ³ eredmÃ©ny (Overfitting illÃºziÃ³ja)
         Vagy nehÃ©z kÃ©pek? 
         â†’ TÃºl rossz eredmÃ©ny (Modell nem jÃ³)
```

**KFold Cross-Validation (JÃ“):**
```
Teljes adathalmaz (433 kÃ©p)
â”œâ”€ FOLD 1: [A-B-C-D | E]  â† E a teszt, A-B-C-D a tanÃ­tÃ¡s
â”œâ”€ FOLD 2: [A-B-C-E | D]  â† D a teszt, A-B-C-E a tanÃ­tÃ¡s
â”œâ”€ FOLD 3: [A-B-D-E | C]  â† C a teszt, A-B-D-E a tanÃ­tÃ¡s
â”œâ”€ FOLD 4: [A-C-D-E | B]  â† B a teszt, A-C-D-E a tanÃ­tÃ¡s
â””â”€ FOLD 5: [B-C-D-E | A]  â† A a teszt, B-C-D-E a tanÃ­tÃ¡s

EREDMÃ‰NY: 5 modell, 5 tesztelÃ©s
         Ãtlag metrika = Igazi teljesÃ­tmÃ©ny (sokkal megbÃ­zhatÃ³bb!)
```

### KFold MÅ±kÃ¶dÃ©si Folyamata

```
1.  ADATHALMAZ FELOSZTÃSA (433 kÃ©p â†’ 5 rÃ©sz, ~87 kÃ©p/fold)
   â”œâ”€ Fold 1: 87 kÃ©p
   â”œâ”€ Fold 2: 86 kÃ©p
   â”œâ”€ Fold 3: 87 kÃ©p
   â”œâ”€ Fold 4: 87 kÃ©p
   â””â”€ Fold 5: 86 kÃ©p

2. ITERÃCIÃ“ (i = 1, 2, 3, 4, 5)
   â””â”€ FOLD i: 
      â”œâ”€ Teszt:  i.  fold (~87 kÃ©p)
      â”œâ”€ TanÃ­tÃ¡s:  tÃ¶bbi 4 fold (~346 kÃ©p)
      â”œâ”€ Modell betanÃ­tÃ¡sa (551 mÃ¡sodperc)
      â”œâ”€ Teszt metrikÃ¡k szÃ¡mÃ­tÃ¡sa: 
      â”‚  â”œâ”€ Loss (vesztesÃ©g)
      â”‚  â”œâ”€ Precision (pontossÃ¡g)
      â”‚  â”œâ”€ Recall (lefedettsÃ©g)
      â”‚  â””â”€ F1 Score (harmonikus Ã¡tlag)
      â””â”€ Modell mentÃ©se (model_fold_i.pth)

3. VÃ‰GEREDMÃ‰NY
   â””â”€ 5 modell + 5 metrika kÃ©szlet
      Ãtlag: 0.866 F1 Score âœ“
```

---

## MetrikÃ¡k Ã‰rtelmezÃ©se

### 1. **Training Time (TanÃ­tÃ¡si idÅ‘)**

```
Fold 1: 551. 11 mÃ¡sodperc = 9 perc 11 mÃ¡sodperc
Fold 2: 551.35 mÃ¡sodperc = 9 perc 11 mÃ¡sodperc
Fold 3: 550.32 mÃ¡sodperc = 9 perc 10 mÃ¡sodperc
Fold 4: 550.62 mÃ¡sodperc = 9 perc 11 mÃ¡sodperc
Fold 5: 551.11 mÃ¡sodperc = 9 perc 11 mÃ¡sodperc
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ãtlag:   550.90 mÃ¡sodperc
STD:    0.41 mÃ¡sodperc (SZUPERB konzisztencia!)
```

**Ã‰rtelmezÃ©s:**
- âœ… Rendre ~551 mÃ¡sodperc = Stabil tanÃ­tÃ¡s
- âœ… Â±1 mÃ¡sodperc eltÃ©rÃ©s = ReprodukÃ¡lhatÃ³ eredmÃ©nyek
- âœ… GPU/CPU terhelÃ©s konzisztens

---

### 2. **Average Loss (Ãtlagos VesztesÃ©g)**

```
Loss fÃ¼ggvÃ©ny = MÃ©rje meg:  "Milyen rossz a jÃ³slÃ¡s?"
```

**Adataink Loss Ã©rtÃ©kei:**
```
Fold 1: 0.0653 âœ“ JÃ³
Fold 2: 0.0629 âœ“ KivÃ¡lÃ³ (LEGJOBB)
Fold 3: 0.0650 âœ“ JÃ³
Fold 4: 0.0652 âœ“ JÃ³
Fold 5: 0.0679 âš ï¸  Kicsit magasabb
â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ãtlag:  0.06526 âœ“ NAGYON JÃ“ (< 0.07)
```

**MiÃ©rt magas a Fold 5?**
- LehetÅ‘sÃ©g 1: Fold 5 adatai "nehezebb" (sÃ¶tÃ©t, elmosÃ³dott kÃ©pek)
- LehetÅ‘sÃ©g 2: VÃ©letlensÃ©g (random inicializÃ¡ciÃ³)
- LehetÅ‘sÃ©g 3: TanÃ­tÃ¡si szÃ³rÃ¡son belÃ¼li vÃ¡ltozat

**VesztesÃ©g Trend:**
- IdeÃ¡lis: Loss monoton csÃ¶kkenÅ‘ â†’ konvergencia âœ“
- ProblÃ©mÃ¡s: Loss nem csÃ¶kken â†’ modell nem tanul
- VeszÃ©lyes: Loss nÃ¶vekszik â†’ Overfitting vagy nem megfelelÅ‘ LR

---

### 3. **Precision (PontossÃ¡g)**

```
                    Helyesen detektÃ¡lt rendszÃ¡mok
Precision = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
             Ã–sszes detektÃ¡lÃ¡s (helyesen + hibÃ¡s)
```

**Adataink Precision Ã©rtÃ©kei:**
```
Fold 1: 0.8113 (81%) âœ“ JÃ³
Fold 2: 0.8000 (80%) âœ“ JÃ³
Fold 3: 0.7965 (80%) âœ“ JÃ³
Fold 4: 0.8624 (86%) â­ LEGJOBB
Fold 5: 0.7350 (74%) ğŸ”´ GYENGÃ‰BB
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ãtlag:  0.80104 (80%) âœ“ ElfogadhatÃ³
```

**Fold 5 AnomÃ¡lia:**
- 74% Precision = A detektÃ¡lÃ¡sok ~26%-a HIBÃS (hamis pozitÃ­v)
- Ez alacsonyabb az Ã¡tlagnÃ¡l 6-7 szÃ¡zalÃ©kponttal
- LehetsÃ©ges:  A teszt kÃ©pei problÃ©mÃ¡sak (alacsony minÅ‘sÃ©g, ferde szÃ¶g)

**Precision KritÃ©riumok:**
- 0.90+: KivÃ¡lÃ³ (professzionÃ¡lis rendszerek)
- 0.80-0.90: JÃ³ (legtÃ¶bb projekt)
- 0.70-0.80: ElfogadhatÃ³ (fejlesztÃ©sben lÃ©vÅ‘)
- <0.70: Gyenge (ÃºjratanÃ­tÃ¡s szÃ¼ksÃ©ges)

---

### 4. **Recall (LefedettsÃ©g)**

```
                      Helyesen detektÃ¡lt rendszÃ¡mok
Recall = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          Ã–sszes valÃ³di rendszÃ¡m a kÃ©peken
```

**ValÃ³s PÃ©lda:**

```
KÃ©pen 10 autÃ³ van, mindegyiknek 1 rendszÃ¡ma:
  â†’ 10 valÃ³di rendszÃ¡m a kÃ©peken

Modell detektÃ¡lÃ¡sa:
  âœ“ 9 IGAZ POZITÃV (helyesen talÃ¡lt)
  âœ— 1 HAMIS NEGATÃV (nem Ã©szlelt!)

Recall = 9 / 10 = 0.90 (90%)
```

**Adataink Recall Ã©rtÃ©kei:**
```
Fold 1: 0.9149 (91%) âœ“ Nagyon jÃ³
Fold 2: 0.9565 (96%) â­ Szuperb
Fold 3: 0.9574 (96%) â­ Szuperb
Fold 4: 0.9592 (96%) â­ Szuperb (LEGJOBB)
Fold 5: 0.9247 (92%) âœ“ Nagyon jÃ³
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ãtlag:  0.94254 (94%) ğŸ† KIVÃLÃ“! 
```

**Mit jelent a 94% Recall?**
- A kÃ©peken lÃ©vÅ‘ rendszÃ¡mok kÃ¶zÃ¼l ~94%-ot felismer
- Ãtlagosan minden 100 rendszÃ¡m kÃ¶zÃ¼l 6-at **missz** (nem talÃ¡l)
- Ez NAGYON JÃ“ az object detection feladatokhoz! 

**Recall vs Precision Kompromisszum:**
```
MAGAS RECALL (de alacsony PRECISION):
  â”œâ”€ Minden rendszÃ¡mot talÃ¡l
  â”œâ”€ De sok hamis detektÃ¡lÃ¡s (zajos)
  â””â”€ IdeÃ¡lis:  BiztonsÃ¡gi kamerÃ¡k (nem szabad kimaradni)

MAGAS PRECISION (de alacsony RECALL):
  â”œâ”€ Csak biztos detektÃ¡lÃ¡sokat csinÃ¡l
  â”œâ”€ De nÃ©hÃ¡nyat kihagy
  â””â”€ IdeÃ¡lis:  Jogi bizonyÃ­tÃ©kok (csak igazi talÃ¡latok!)

KIEGYENSÃšLYOZOTT (magas RECALL + PRECISION):
  â”œâ”€ KevÃ©s hibÃ¡t, kevÃ©s kimaradÃ¡st
  â”œâ”€ Nagyon nehÃ©z elÃ©rni
  â””â”€ IdeÃ¡lis:  LegtÃ¶bb alkalmazÃ¡s
```

---

### 5. **F1 Score (Harmonikus Ãtlag)**

```
           2 Ã— Precision Ã— Recall
F1 = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      Precision + Recall
```

**MiÃ©rt Harmonikus Ãtlag?**

Ã–sszehasonlÃ­tÃ¡s:
```
MÃ³dszer A:  Precision=0.9, Recall=0.1 â†’ Ãtlag=(0.9+0.1)/2=0.5
                                       F1=2Ã—0.9Ã—0.1/(0.9+0.1)=0.18

MÃ³dszer B: Precision=0.5, Recall=0.5 â†’ Ãtlag=(0.5+0.5)/2=0.5
                                       F1=2Ã—0.5Ã—0.5/(0.5+0.5)=0.5

LÃTHATÃ“: A "kiegyensÃºlyozatlan" (A) rosszabb F1-et kap,
         bÃ¡r az Ã¡tlaga azonos! 
         Az F1 BÃœNTETI az extrÃ©m eloszlÃ¡sokat.
```

**Adataink F1 Score Ã©rtÃ©kei:**
```
Fold 1: 0.8600 (86%) âœ“ JÃ³
Fold 2: 0.8713 (87%) âœ“ JÃ³
Fold 3: 0.8696 (87%) âœ“ JÃ³
Fold 4: 0.9082 (91%) â­ KIVÃLÃ“ (LEGJOBB)
Fold 5: 0.8190 (82%) âš ï¸  GyengÃ©bb
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ãtlag:  0.86562 (87%) âœ“ ERÅS MODELL
```

**F1 Score Ã‰rtelmezÃ©se:**

```
0.90+: Szuperb (professzionÃ¡lis)         ğŸ†
0.85-0.90: ErÅ‘s (jÃ³ projekt)             âœ“ â† MI
0.75-0.85: ElfogadhatÃ³ (fejlesztÃ©sben)   âš ï¸
0.65-0.75: Gyenge (reworking szÃ¼ksÃ©ges)  ğŸ”´
<0.65: Nem hasznÃ¡lhatÃ³                   âŒ
```

---

## EredmÃ©nyek ElemzÃ©se

### Teljes Metrika TÃ¡blÃ¡zat

| Fold | Model | Train Time (s) | Avg Loss | Precision | Recall | F1 Score | Status |
|------|-------|-----------------|----------|-----------|--------|----------|--------|
| 1 | fold_1.pth | 551.11 | 0.0653 | 0.8113 | 0.9149 | 0.8600 | âœ“ |
| 2 | fold_2.pth | 551.35 | 0.0629 | 0.8000 | 0.9565 | 0.8713 | âœ“ |
| 3 | fold_3.pth | 550.32 | 0.0650 | 0.7965 | 0.9574 | 0.8696 | âœ“ |
| 4 | fold_4.pth | 550.62 | 0.0652 | 0.8624 | 0.9592 | 0.9082 | â­ |
| 5 | fold_5.pth | 551.11 | 0.0679 | 0.7350 | 0.9247 | 0.8190 | âš ï¸ |
| **Ãtlag** | - | **550.90** | **0.06526** | **0.80104** | **0.94254** | **0.86562** | **âœ“** |

---

### ğŸŒŸ Kiemelt MegÃ¡llapÃ­tÃ¡sok

#### âœ… ErÅ‘ssÃ©gek (PozitÃ­v Jelek)

**1. Szuperb Recall (94. 25%)**
```
A modell szinte MINDIG megtalÃ¡lja a rendszÃ¡mokat! 
Csak ~6 az 100-bÃ³l marad el. 
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Legjobb a rendszÃ¡mfelismerÃ©shez       â•‘
â•‘ (nem szabad kimaradni!)               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**2. Konzisztens TanÃ­tÃ¡si IdÅ‘**
```
Fold-ok kÃ¶zÃ¶tt max Â±1 mÃ¡sodperc eltÃ©rÃ©s! 
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Stabil GPU terhelÃ©s                   â•‘
â•‘ ReprodukÃ¡lhatÃ³ eredmÃ©nyek             â•‘
â•‘ (lehet bizni a modellben)             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**3. Alacsony Loss (0.065)**
```
Modell jÃ³l megtanult a feature-Ã¶ket!
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Nincs overfitting jel                 â•‘
â•‘ (Loss nem nÃ¶vekszik tesztnÃ©l)         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**4. KiegyensÃºlyozott F1 (0.866)**
```
Sem Precision, sem Recall nem dominÃ¡l!
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Praktikus, Ã©les alkalmazÃ¡shoz kÃ©sz    â•‘
â•‘ (legtÃ¶bb feladathoz ideÃ¡lis)          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

#### âš ï¸ FejlesztÃ©si LehetÅ‘sÃ©gek

**1. Precision JavÃ­tÃ¡sa (jelenleg 80. 1%)**

```
ProblÃ©ma: ~20% hamis pozitÃ­v
         (nem-rendszÃ¡mokat rendszÃ¡mnak hisz)

Okok lehetsÃ©gesek:
  â”œâ”€ TÃºl alacsony confidence threshold
  â”œâ”€ Modell nem megbÃ­zhatÃ³ "edge case"-ekben
  â””â”€ Postprocessing hiÃ¡nya

MegoldÃ¡sok:
  â”œâ”€ Non-Maximum Suppression (NMS) tuning
  â”‚  â””â”€ Overlap threshold (IOU) csÃ¶kkentÃ©se
  â”œâ”€ Confidence Threshold nÃ¶velÃ©se
  â”‚  â””â”€ De:  Recall csÃ¶kkenhet! 
  â”œâ”€ Hard Negative Mining
  â”‚  â””â”€ Hamis pozitÃ­vokra plusz tanÃ­tÃ¡s
  â””â”€ Ensemble (Fold 2+4 kombinÃ¡lÃ¡sa)
     â””â”€ SzavazÃ¡sos dÃ¶ntÃ©s = magasabb pontossÃ¡g
```

**2. Fold 5 AnomÃ¡lia VizsgÃ¡lata**

```
Fold 5: 73.5% Precision (6. 6% alacsonyabb az Ã¡tlagnÃ¡l!)
        0.0679 Loss (a legmagasabb)

Mit jelent? 
  â”œâ”€ Ez az "test split" nehezebb lehet
  â”œâ”€ KÃ¼lÃ¶nleges kÃ©pek lehetnek (rossz minÅ‘sÃ©g/szÃ¶g)
  â””â”€ Adathalmaz heterogÃ©n? 

Mit tennÃ©l?
  â”œâ”€ Fold 5 kÃ©peinek analÃ­zise
  â”œâ”€ KÃ©pklaszterezÃ©s (hasonlÃ³ak csoportosÃ­tÃ¡sa)
  â”œâ”€ Difficult flag annotÃ¡ciÃ³k hozzÃ¡adÃ¡sa
  â””â”€ Ezeken plusz tanÃ­tÃ¡s
```

---

### ğŸ¯ Fold 4 â€“ A Legjobb Modell

```
Fold 4 Az Ã‰v Modellje!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Metrika        | Ã‰rtÃ©k  | StÃ¡tusz
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Precision      | 0.8624 | ğŸ† LEGJOBB
Recall         | 0.9592 | ğŸ† SZUPERB
F1 Score       | 0.9082 | ğŸ† LEGJOBB
Loss           | 0.0652 | âœ“ JÃ³
Training Time  | 550.62 | âœ“ NormÃ¡l

TulajdonsÃ¡g: KivÃ¡lÃ³ egyensÃºly precision-recall kÃ¶zÃ¶tt! 

Javaslat: Ez legyen a PRODUKCIÃ“S MODELL!
```

---

## Javaslatok Ã©s FejlesztÃ©si IrÃ¡nyok

### 1. **Immediate (Azonnali) FejlesztÃ©sek**

#### A. Non-Maximum Suppression (NMS) FinomhangolÃ¡sa
```python
def apply_nms(detections, iou_threshold=0.5):
    """
    DuplikÃ¡lt detektÃ¡lÃ¡sok eltÃ¡volÃ­tÃ¡sa. 
    """
    # Ha 2 box >= 0.5 IOU, megtartjuk az egyiket (magasabb confidence)
    # Ez CSÃ–KKENTI a hamis pozitÃ­vokat! 
```

**HatÃ¡s:**
- Precision: 80% â†’ 85-90%
- Recall: 94% â†’ 93-94% (kicsit csÃ¶kken, de elfogadhatÃ³)

---

#### B. Confidence Threshold OptimizÃ¡lÃ¡sa
```python
# Jelenleg:  score >= 0.5 akkor detektÃ¡lÃ¡s
# PrÃ³bÃ¡ld:  score >= 0.6 vagy 0.7

# Trade-off: 
# - score >= 0.5: Magas recall, alacsony precision (most mi)
# - score >= 0.7: Alacsony recall, magas precision
# - score >= 0.6: KÃ¶zÃ©pÃºt (lehet ideÃ¡lis)
```

**Javasolt FelhasznÃ¡lÃ¡si Eset:**
- ParkolÃ³automatika: 0.6 (biztos detektÃ¡lÃ¡s szÃ¼ksÃ©ges)
- BiztonsÃ¡gi kamera: 0.5 (ne maradjon el semmi)
- Jogi bizonyÃ­tÃ©k: 0.8 (csak abszolÃºt biztos)

---

#### C. Ensemble Voting
```python
# 5 modell helyett hasznÃ¡lj:  Fold 2 + Fold 4
# Logika: 
#   â”œâ”€ Ha mindkettÅ‘ detektÃ¡l â†’ Igazi detektÃ¡lÃ¡s (confidence++)
#   â”œâ”€ Ha csak egyik â†’ Bizonytalan (threshold alapÃº dÃ¶ntÃ©s)
#   â””â”€ Egyik sem â†’ Nincs detektÃ¡lÃ¡s

# ElÅ‘ny:  ~5-10% precision javulÃ¡s
# HÃ¡trÃ¡ny: 2x lassabb inference
```

---

### 2. **Medium Term (KÃ¶zepes TÃ¡von)**

#### A. Hard Negative Mining
```
Hard Negative Mining = MegtanÃ­tani a modellt az "szinte rendszÃ¡m" kÃ©pekre

LÃ©pÃ©sek:
1. TanÃ­tsd a modellt (mÃ¡r megvan!)
2. Futtasd az Ã¶sszes kÃ©pen
3. GyÅ±jtsd Ã¶ssze a hamis pozitÃ­vakat
4. AnnotÃ¡ld Å‘ket (NEM = nincs rendszÃ¡m)
5. Adjuk a tanÃ­tÃ³halmaz NEGATÃV mintÃ¡ihoz
6. Retrain (plusz 50 epoch)

HatÃ¡s:  
  â”œâ”€ Precision: 80% â†’ 87-92%
  â”œâ”€ Recall: 94% â†’ 92-94% (minimÃ¡lis csÃ¶kkenÃ©s)
  â””â”€ F1: 0.866 â†’ 0.900+ â­
```

---

#### B. Adat AugmentÃ¡ciÃ³ ErÅ‘sÃ­tÃ©se
```python
# Jelenleg: 
# - ColorJitter: brightness=0.4
# - Noise: 0.05 std
# - Blur: kernel=5Ã—9

# Javasolt erÅ‘sÃ­tÃ©s:
transforms. append(T.RandomRotation(degrees=10))     # Â±10Â° forgatÃ¡s
transforms.append(T. RandomAffine(degrees=0, translate=(0.1, 0.1)))  # eltolÃ¡s
transforms.append(T. RandomPerspective(distortion_scale=0.2))  # perspektÃ­va
```

**ElÅ‘ny:**
- Modell robusztusabbÃ¡ vÃ¡lik
- ValÃ³svilÃ¡gszerÅ±bb szituÃ¡ciÃ³k (dÃ¶ntÃ¶tt autÃ³, szÃ¶g)
- Overfitting csÃ¶kkentÃ©s

---

#### C. Fine-tuning Nagyobb Modellel
```
Jelenleg:  Ismeretlen modell (feltehetÅ‘en Faster R-CNN vagy YOLOv5)

Javaslat: PrÃ³bÃ¡ld a nagyobb "backbone" (gerinc) verziÃ³t
- ResNet-50 â†’ ResNet-101 (tÃ¶bb paramÃ©ter)
- YOLOv5s â†’ YOLOv5m vagy v5l

HatÃ¡s:
  â”œâ”€ Precision/Recall: +2-5%
  â”œâ”€ Training Time: +30-50% (mÃ©g elfogadhatÃ³)
  â””â”€ SzÃ¼ksÃ©ges GPU:  Magasabb, de Kaggle kezelheti
```

---

### 3. **Long Term (HosszÃº TÃ¡von)**

#### A. SajÃ¡t Adathalmaz BÅ‘vÃ­tÃ©se
```
433 kÃ©p â†’ 1000+ kÃ©p

Hogyan szerezzÃ©tek?
  â”œâ”€ Internet kÃ©pekhez link gyÅ±jtÃ©s (creative commons)
  â”œâ”€ SajÃ¡t felvÃ©telek (autÃ³parkolÃ³ kamera)
  â”œâ”€ SzintÃ©zissel (GAN generÃ¡lt kÃ©pek) - modern megkÃ¶zelÃ­tÃ©s
  â””â”€ Data labeling service (Mechanical Turk, local annotators)

HatÃ¡s:
  â”œâ”€ 433 â†’ 1000: +5-10% accuracy
  â”œâ”€ 433 â†’ 5000: +15-20% accuracy
  â””â”€ 433 â†’ 10000+: +25-30% accuracy (kÃ¶zvetÃ­tlenÃ¼l mÃ©rhetÅ‘)
```

---

#### B. Domain Adaptation (TartomÃ¡ny AdaptÃ¡ciÃ³)
```
ProblÃ©ma: A Kaggle adathalmaz speciÃ¡lis
         (lehet mÃ¡s orszÃ¡gbÃ³l, speciÃ¡lis autÃ³k)
         
MegoldÃ¡s:  Transfer Learning
  1. Pretrained ImageNet modell (10 milliÃ³ kÃ©p, Ã¡ltalÃ¡nos)
  2. Fine-tune a sajÃ¡t adathalmazon
  3. Ezt csinÃ¡ljÃ¡tok mÃ¡r (valszleg!)
  
HaladÃ³:  Unsupervised Domain Adaptation
  1. Target domain kÃ©pek betÃ¶ltÃ©se (Ãºj orszÃ¡g, Ãºj autÃ³k)
  2. Modell adaptÃ¡lÃ¡sa anÃ©lkÃ¼l, hogy annotÃ¡lnÃ¡nk
  3. SzakÃ©rtÅ‘i AI technika (de lehetsÃ©ges!)
```

---

#### C. Ensemble + Stacking

```
Ensemble = TÃ¶bb modell szavazÃ¡sa
Stacking = A modellek kimenete egy meta-modelbe megy

ArchitektÃºra: 
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Input KÃ©p (Auto)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
     â”‚       â”‚       â”‚
   â”Œâ”€â–¼â”€â”  â”Œâ”€â–¼â”€â”  â”Œâ”€â–¼â”€â”
   â”‚ M1â”‚  â”‚ M2â”‚  â”‚ M3â”‚  â† 3 kÃ¼lÃ¶nbÃ¶zÅ‘ modell
   â”‚   â”‚  â”‚   â”‚  â”‚   â”‚    (Fold 1, 4, 2)
   â””â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜
     â”‚      â”‚      â”‚
     â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜
            â”‚
         â”Œâ”€â”€â–¼â”€â”€â”
         â”‚Meta â”‚      â† Egy "tanÃ¡r" modell, amely
         â”‚Modelâ”‚        Ã¶sszefogja az eredmÃ©nyeket
         â””â”€â”€â”€â”€â”€â”˜
```

**ElÅ‘ny:**
- Precision: +5-8%
- Recall: +2-3%
- F1: 0.866 â†’ 0.91-0.94

**HÃ¡trÃ¡ny:**
- 3x lassabb (3 modell inference)
- Komplex Ã¼zemeltetÃ©s

---

## ğŸ“‹ Ã–sszefoglalÃ¡s Ã©s KonklÃºziÃ³

### Mit Ã©pÃ­tettÃ¼nk? 

âœ… **Teljes Object Detection Pipeline:**
- Adat betÃ¶ltÃ©s + annotÃ¡ciÃ³ parsing
- AugmentÃ¡ciÃ³ (zaj, blur, szÃ­n-variÃ¡ciÃ³)
- Custom PyTorch Dataset
- KFold Cross-Validation
- Metrika szÃ¡mÃ­tÃ¡s

âœ… **EredmÃ©ny:**
- F1 Score: 0.866 (ErÅ‘s teljesÃ­tmÃ©ny!)
- Recall: 94. 25% (Szinte mindig talÃ¡l rendszÃ¡mot)
- Precision: 80.1% (NÃ©hÃ¡ny hamis pozitÃ­v van)
- Konzisztens, stabil tanÃ­tÃ¡s

---

### Ã‰les ProdukciÃ³hoz KÃ©sz? 

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KIFEJLESZTÃ‰SI FÃZIS:  âœ“ KÃ‰SZ            â”‚
â”‚  BEVEZETÃ‰SRE KÃ‰SZ: âš ï¸ FELTÃ‰TELESEN      â”‚
â”‚                                          â”‚
â”‚  Fold 4 Modellfold_4.pth                 â”‚
â”‚  MetrikÃ¡k:                                 â”‚
â”‚  â”œâ”€ Precision: 86.24% âœ“                 â”‚
â”‚  â”œâ”€ Recall: 95.92% âœ“                    â”‚
â”‚  â”œâ”€ F1: 90.82% âœ“                        â”‚
â”‚  â””â”€ Loss: 0.0652 âœ“                      â”‚
â”‚                                          â”‚
â”‚  FELTÃ‰TELEK:                             â”‚
â”‚  â”œâ”€ [ ] NMS finomhangolÃ¡s               â”‚
â”‚  â”œâ”€ [ ] Hard Negative Mining             â”‚
â”‚  â”œâ”€ [ ] Fold 5 debug                     â”‚
â”‚  â”œâ”€ [ ] Monitoring Ã©s logolÃ¡s            â”‚
â”‚  â””â”€ [ ] A/B testing (rÃ©gi vs Ãºj modell)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### VÃ©gsÅ‘ Javaslat

```
ğŸ¯ KÃ–ZVETLEN CSELEKVÃ‰S PRIORITÃS:

1. â­â­â­ MAGAS PRIORITÃS:
   â””â”€ Fold 4 modell Ã©les environment-be (pilot)
   â””â”€ NMS tuning + confidence threshold
   
2. â­â­ KÃ–ZEPES PRIORITÃS:
   â””â”€ Hard Negative Mining
   â””â”€ Fold 5 adatainak analÃ­zise
   
3. â­ ALACSONY PRIORITÃS:
   â””â”€ Ensemble voting
   â””â”€ Nagyobb modell prÃ³bÃ¡lgatÃ¡sa
```

---

## ğŸ“ ReferenciÃ¡k Ã©s Hasznos Linkek

- **PyTorch DokumentÃ¡ciÃ³**: https://pytorch.org/docs/stable/index.html
- **Torchvision Object Detection**: https://pytorch.org/vision/stable/models.html
- **KFold DokumentÃ¡ciÃ³**: https://scikit-learn.org/stable/modules/generated/sklearn. model_selection.KFold. html
- **Object Detection MetrikÃ¡k**: https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a270f0
- **NMS MagyarÃ¡zat**: https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/
